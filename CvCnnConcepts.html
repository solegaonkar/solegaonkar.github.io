<!DOCTYPE html><html><head><title>CNN Concepts</title><script src="scripts/index.js"></script></head><body><h1>CNN Concepts</h1><hr/><p><a href="https://thewiz.net"><h4>TheWiz.Net</h4></a></p><p>Having seen a top level view of CNN, let us take another step forward. Here are some of the important concepts that we should know before we go further into using CNN.</p><h4>Padding</h4><hr/><p>One visible problem with the Convolution Filter is that each step reduces the "information" by reducing the matrix size - shrinking output. Essentially, if the original matrix is N x N, and the filter is F x F, the resulting matrix would be (N - F + 1) x (N - F + 1). This is because the pixels on the edges are used less than the pixels in the middle of the image.</p><p>If we pad the image by (F - 1)/2 pixels on all sides, the size of N x N will be preserved.</p><p>Thus we have two types of convolutions, Valid Convolution and Same Convolution. Valid essentially means no padding. So each Convolution results in reduction in the size. Same Convolution uses padding such that the size of the matrix is preserved.</p><p>In computer vision, F is usually odd. So this works well. Odd F helps retain symmetry of the image and also allows for a center pixel that helps in various algorithms to apply a uniform bias. Thus, 3x3, 5x5, 7x7 filters are quite common. We also have 1x1 filters.</p><h4>Strided Convolution</h4><hr/><p>The convolution we discussed above is continuous in the sense that it sweeps the pixels continuously. We can also do it in strides - by skipping s pixels when moving the convolution filter across the image.</p><p>Thus, if we have n x n image and f x f filter and we convolve with a stride s and padding p, the output is:</p><pre><code class='python'>((n + 2p -f)/s + 1) x ((n + 2p -f)/s + 1)</code></pre><p>Ofcourse if this is not an integer, we would have to chop it down.</p><h4>Convolution v/s Cross Correlation</h4><hr/><p>Cross Correlation is essentially convolution with the matrix flipped over the bottom-top diagonal. Flipping adds the Associativity to the operation. But in image processing, we do not flip it.</p><h4>Convolution on RGB images</h4><hr/><p>Now we have an n x n x 3 image and we convolve it with f x f x 3 filter. Thus we have a height, width and number of channels in any image and its filter. At any time, the number of channels in the image is same as the number of channels in the filter. The output of this convolution has width and height of (n - f + 1) and 1 channel.</p><h4>Multiple Filters</h4><hr/><p>A 3 channel image convolved with a three channel filter gives us a single channel output. But we are not restricted to just one filter. We can have multiple filters - each of which results in a new layer of the output. Thus, the number of channels in the input should be the same as the number of channels in each filter. And the number of filters is the same as the number of channels in the output.</p><p>Thus, we start with 3 channel image and end up with multiple channels in the output. Each of these output channel represents some particular aspect of the image that is picked up by the corresponding filter. Hence it is also called a feature rather than a channel. In a real deep network, we also add a bias and a non linear activation function like RelU.</p><h4>Pooling Layers</h4><hr/><p>Pooling is essentially combining values into one value. We could have average pooling, max pooling, min pooling, etc. Thus a nxn input with pooling of fxf will generate (n/f)x(n/f) output. It has no parameters to learn.</p><div class='center'><img src='img/MaxPooling.png' /></div></body><script>loadPageFormat();</script></html>