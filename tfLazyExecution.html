<!DOCTYPE html><html><head><title>Lazy Execution</title><script src='scripts/index.js'></script></head><body><h1>Lazy Execution</h1><hr/><p><a href="">TheWiz.Net</a></p>

<p>By design, TensorFlow is based on lazy execution (though we can force eager execution). That means, it does not actually process the data available till it has to. It just gathers all the information that we feed into it. It processes only when we finally ask it to process.</p><p>Such laziness (ironically) provides a huge improvement in the processing speed. To understand how, we need to understand the Nodes and Graphs of TensorFlow.</p><h3>Nodes</h3><hr/><div class='center'><img src='img/mlp_one_hidden_layer.png' /></div><p>This is the textbook view of a neural network. As we can see, we have several inputs X<sub>1</sub> - X<sub>n</sub>. These form the first layer of the network. The second (hidden) layer is obtained as a dot product of each of these with the weight matrix, followed by the activation function like sigmoid or relu.</p><p>The third layer is just one value that is obtained as a dot product of its weight matrix with the output of the second layer.</p><p>For TensorFlow, each of these individual entities is a Node. The the first layer has n+1 nodes (n inputs and 1 constant). The second layer has k+1 nodes and the third layer has 1 node. Each of these nodes is represented by a Tensor.</p><h3>Graph</h3><hr/><p>We can see that some nodes have a constant value (e.g. the bias 1). Some of them have variable values like the weight matrix - we start with a random initialization and tune it through the process. And we have some nodes whose value is just based on some computation on the other nodes - these are dependent nodes - we cannot get their values until we have the values of the previous nodes.</p><p>In this network, we have k nodes in the middle layer and 1 node in the last layer that depend on other nodes - we have k+1 dependent nodes and k variables that we need to tune.</p><h3>Compilation</h3><hr/><p>When we create individual Tensors, we just create individual nodes and assign the define the relations - these relations are yet to be implemented. Once we are done with the definitions, we initiate the compile() method, that identifies this graph connecting the nodes.</p><p>This is an important step in the whole process. If we have circular dependencies or any other reason that could break the graph, the error is identified at this point.</p><h3>Session</h3><hr/><p>The TensorFlow computations are always executed in a "session". A Session is essentially an environment with a status of its own. Session is not a thread, but if we have two independent computations that need to run together - without influencing each other, we can use sessions.</p><pre><code class='python'>sess1.run(A)
sess2.run(B)
sess1.run(C)
sess2.run(D)</code></pre><p>Here, A and C will run under session 1, and will see one environment and B and D will run in the session 2 - and see another environment.</p><p>Once we have defined the nodes and compiled the graph, we can finally run the command to get value of a particular node in the graph. When we do so, TensorFlow looks back to check all the nodes that are required for this requested node. Only those nodes are evaluated in the appropriate order. Thus, a node in the graph is evaluated only when needed; only if it is needed.</p><p>This has a great impact on the processing speed and is a major advantage of TensorFlow.</p>

</body><script>loadPageFormat();</script></html>
