<!DOCTYPE html><html><head><title>Factor Analysis</title><script src='scripts/index.js'></script></head><body><h1>Factor Analysis</h1><hr/><p><a href="">TheWiz.Net</a></p>

<p>Factor Analysis performs dimensionality reduction on principles similar to high correlation filter. But it is more efficient. If the correlation between two parameters is too high, we can just skip one of them. But often, we end up with a scenario where the correlation is quite good, but not so high that we can just discard one of them.</p><p>Consider for example, the four parameters - education, experience, salary and bank balance. These are certainly not independent. But each of them contributes some information. We can not just discard any of them. Factor Analysis is a statistical technique that identifies the underlying hidden parameters that are independent (hence lesser in number).</p><p>These hidden parameters may not have any particular significance in the real world. But they can be combined to generate the set of correlated parameters that we have.</p><p>Of course, the mathematical implementation is not as simple as the concept. But we really don't have to worry about it. SktLearn and many other Python libraries provide us a simple implementation for it.</p><h3>Python Code</h3><hr/><p>SktLearn has a module FactorAnalysis that provides a simple implementation. We can configure it to specify the number of components we want from the available data.</p><pre><code class='python'>from sklearn.decomposition import FactorAnalysis
FA = FactorAnalysis(n_components = 3).fit_transform(df[feat_cols].values)</code></pre><p>That is all we need. It will extract and pass on the components to the FA data frame.</p>

</body><script>loadPageFormat();</script></html>
