<!DOCTYPE html><html><head><title>The Jargon</title><script src='scripts/index.js'></script></head><body><h1>The Jargon</h1><hr/><p><a href="">TheWiz.Net</a></p>

<p>Machine learning comes with a big jargon. And Techies enjoy acronyms that make understanding even more difficult. Here are some of the most common terms that people talk about.</p><h3>AI &amp; Machine Learning</h3><hr/><p>What exactly do these mean? AI - Artificial Intelligence - is the most generic term. It is the branch of science that attempts to externalize intelligence - the ability to take decisions. Artificial Intelligence is a concept. Machine Learning is one particular implementation of this concept of Artificial Intelligence.</p><p>Machine Learning is a bunch of techniques that enable machines learn from available data; and use this learning in various applications. </p><p>There are several kinds of machine learning algorithms. Each presenting a trade-off between ability and cost.  Note that machine learning algorithms are purely software applications. It is a piece of code that takes an input and produces output. In this case, the input is called the training data while the output is called a trained model.</p><p>The concepts of machine learning and artificial intelligence are not new. But until more a decade ago, they were restricted to the academic world. Machine learning requires massive computational resources and huge amount of data to make any meaningful application. The recent developments in electronics have given us a lot of processing power and the massive social media industry has provided us the required data source. This has brought us to a point where we can meaningfully apply the concepts we have preserved so long. </p><h3>Neural Networks</h3><hr/><p>This is one of the most popular machine learning algorithm. It was inspired by the human nervous system works. In its implementation, this neural network is purely a software data structure - a model that is trained based on the available data. This requires intensive mathematical computations and hence a very high processing power.</p><p>The neural networks do not have a theoretical limit on their capacity. They can get more and more complex and continue to grow in their ability to learn and perform. Although the concept of neural networks is pretty old, the huge flow of data and developments in the processing power have enabled us to use them more and more. Enhancements in neural networks have been the primary driving factor in the miraculous inventions we have seen in the world of artificial intelligence</p><h3>Computer Vision</h3><hr/><p>Computer vision is the branch of AI that deals with identifying and processing images - enabling sight in the machines. We typically store images in pixels. But the content of an image is not bound to the pixels. A slight shift in the image a minor shadow would completely change the pixel data. But the content of the image remains unchanged. </p><p>The modern day computer vision algorithms can identify faces to an amazing accuracy. We have algorithms that can project 3 D models from a simple 2 D image. It can auto correct missing parts of images. And a lot more. All these are thanks to the developments in computer vision.</p><h3>Natural Language Processing</h3><hr/><p>There is almost no logic to any language that humans speak. Most of our languages have evolved over time - based on convenience and random acceptance. (Only exception is Sansrit that was formally created and finalized before it could be used). One can never produce an algorithm that can map an English sentence to its meaning. Yet, the mind has absolutely no problem doing this job! How does it manage this?</p><p>NLP is the branch of machine learning that focuses on trying to understand the mind's way of working with a language and producing sentences. </p><p>In our speech, just a few words do not convey all the meaning. The meaning of a word is in relation to the sentence, and the sentences before and the events that occurred before and the events that happened years ago... that could trace back to the big bang itself! The meaning of anything that we say today can be entirely different in the context of an event in the past.</p><p>Natural Language Processing works on resolving these aspects of learning.</p><h3>Bots</h3><hr/><p>This is an extension of natural language processing. These are gadgets and applications that can converse with humans. What we see today is far from perfection, yet no less amazing. </p><p>Considering the wide range of applications to such bots, researchers have created dedicated architectures and frameworks for building such bots. Now we do not have to start from the basics. AWS, IBM, Google, Azure.. each provides wonderful API for building one very quickly. The open source community is no less active in this domain and we have several python frameworks that can do the job for us.</p><p>With many new bot-based products flowing into the market. Bots seem to be the upcoming big boom in the industry.</p><h3>Google Brain</h3><hr/><p>All the AI applications that we have today, focus on one kind of input - sound, images, words.. We do not have a way to deal with all of them together. All our models are independently trained for individual domains and are applied independently. </p><p>We need more than this. Google Brain is a project that is intended to club together many the different aspects of machine learning into the same model. This is the foremost in the field, but all other players are coming up with their respective approaches for creating a brain.</p>

</body><script>loadPageFormat();</script></html>
