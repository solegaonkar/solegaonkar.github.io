<!DOCTYPE html><html><head><title>What is a Tensor?</title><script src='scripts/index.js'></script></head><body><h1>What is a Tensor?</h1><hr/><p><a href="https://thewiz.net"><h4>TheWiz.Net</h4></a></p>

<p>According to the Wikipedia, "A tensor is a geometric object that maps in a multi-linear manner geometric vectors, scalars, and other tensors to a resulting tensor. Thereby, vectors and scalars themselves, often used already in elementary physics and engineering applications, are considered as the simplest tensors. Additionally, vectors from the dual space of the vector space, which supplies the geometric vectors, are also included as tensors. Geometric in this context is chiefly meant to emphasize independence of any selection of a coordinate system."</p><p>Don't worry it is not that complicated. When working on a problem with multiple variables, it is often convenient to collect them together in form of a vector or a matrix, so that it is easier to perform linear operations on them. Most of machine learning is based on such matrix operations - where a set of input values is processed together to get a set of output values. </p><p>For example, in the good old loan sanction problem, we consider several parameters of the subject (amount of loans taken in past, time taken to return, etc.) and sum them up with appropriate weights - to get an output number called the credit rating. This is implemented using simple <a href="LinearAlgebraMultiplication.html" class='link'>matrix multiplication</a>.</p><p>Such matrix multiplication gives us the result for just one case. When we want to train a neural network with data for a million such cases, we cannot multiply them one by one. That is where Tensors are used. Tensor is a data structure that represents a collection of matrices or vectors that allows us to perform operation on all the data samples at the same time. This gives us a great performance improvement.</p><p>Tensors could be an input value, a constants, a variables or just a reference to a mathematical operation on some other tensors. </p><p>Tensor may be 3D (collection of matrices) or 2D (collection of vectors) or 1D (collection of numbers) or even 0D (a single number). The number of dimensions do not make a Tensor - what is important is the concept of simultaneous operations on multiple entities.</p><h3>Rank</h3><hr/><p>The number of dimensions of the Tensor, is called the Rank of the Tensor. Hence we have several ranks possible.</p><table><tr><th>Rank</th><th>Math entity</th></tr><tr><td>0</td><td>Scalar (magnitude only)</td></tr><tr><td>1</td><td>Vector (magnitude and direction)</td></tr><tr><td>2</td><td>Matrix (table of numbers)</td></tr><tr><td>3</td><td>3-Tensor (cube of numbers)</td></tr><tr><td>n</td><td>n-Tensor (n dimensional structure)</td></tr></table><h3>Constant Tensor</h3><hr/><p>The simplest Tensor is one with a constant value. We can define with the explicit values or using methods defined for the frequently used ones.</p><pre><code class='python'>t1 = tf.constant(1729)        # Constant Tensor with one element with value 1729
t2 = tf.constant([1,8,27,64])         # Constant Tensor of shape 4 with the given values 

t3 = tf.zeros([10,20], tf.float32)    # Constant Tensor of shape [10,20] - with each element set to 0
t4 = tf.zeros_like(t2)                # Constant Tensor of shape and datatype same as t2, with all elements set to 0

t5 = tf.ones([5,6], tf.int32)   # Constant Tensor of shape [5,6] with each value set to 1
t6 = tf.ones_like(t3)           # Constant Tensor of shape and datatype same as t3, with each element set to 1

t7 = tf.eye(10)                 # Identity matrix of size 10

t8 = tf.linspace(1.0, 3.0,5)    # [1.0, 1.5, 2.0, 2.5, 3.0] - Constant tensor with 5 equally spaced values from 1.0 to 3.0
t9 = tf.range(1.0,3.5, 0.5)     # [1.0, 1.5, 2.0, 2.5, 3.0] - Same as Python range. Note that Range excludes last element

t11 = tf.random_normal([4,5], mean = 5.0, stddev = 4, seed=1)   # Constant Tensor of shape [4,5] with random values of defined normal distribution
t12 = tf.random_uniform([4,5], maxval = 4.0, seed = 1)          # Constant Tensor with random values with defined uniform distribution.</code></pre><p>Note that this does not assign the constant values to the Tensor. It only creates the Tensor that can be evaluated when required.</p><h3>Variable Tensors</h3><hr/><p>Constants allow us to create a predefined values that  can be used in computations. But no computation is complete without variables. Training a neural network requires variables that can represent weights to be learnt in the process. These variables can be generated using  the class tf.Variable.</p><pre><code class='python'>weights = tf.Variable(tf.random_normal([10,10], stddev=1))</code></pre><p>This generates a Variable Tensor - weights - that can be trained. But, we can also have Variable Tensors that cannot be altered - just like a constant. </p><pre><code class='python'>constant = tf.Variable(tf.zeros([10,10]), trainable=False)</code></pre><p>What is the use of doing something like that? Why not just define a constant? For a Tensor of 10x10, it makes more sense to create a constant Tensor. But when working with huge sizes, one should prefer variables. That is because variables are a lot more efficiently managed.</p><h3>Placeholders</h3><hr/><p>Constant Tensors and Variable Tensors are intuitively similar to constants and variables in any programming language. That does not take time to understand. The placeholders define Tensors that would get a value just before the code runs. In that sense, a placeholder can be compared to an input parameter.</p><pre><code class='python'>x = tf.placeholder(tf.int32)</code></pre><p>This generates a Tensor x - with an assurance that its value will be provided just before the code actually runs.</p>

</body><script>loadPageFormat();</script></html>
